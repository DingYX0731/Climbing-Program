{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import math\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lib.dataloader import normalize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Keys: <KeysViewHDF5 ['data', 'date']>\n",
      "Data Tensor Shape: torch.Size([4392, 2, 16, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25540\\AppData\\Local\\Temp\\ipykernel_10168\\1030900333.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  data_tensor = torch.tensor(data['data'])\n"
     ]
    }
   ],
   "source": [
    "data = h5py.File('NYCBike1.h5', 'r')\n",
    "print(f\"Data Keys: {data.keys()}\")\n",
    "data_tensor = torch.tensor(data['data'])\n",
    "print(f\"Data Tensor Shape: {data_tensor.shape}\")\n",
    "tensor = torch.reshape(data_tensor, (data_tensor.shape[0], data_tensor.shape[1], 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Tensor Shape: torch.Size([4315, 19, 128, 2])\n",
      "Y Tensor Shape: torch.Size([4315, 1, 128, 2])\n"
     ]
    }
   ],
   "source": [
    "x_tensor = None\n",
    "y_tensor = None\n",
    "for i in range(tensor.size(0)-77):\n",
    "    window_list = [\n",
    "        tensor[i:i+5],\n",
    "        tensor[i+24:i+29],\n",
    "        tensor[i+48:i+53],\n",
    "        tensor[i+72:i+76]\n",
    "    ]\n",
    "    if x_tensor is None:\n",
    "        x_tensor = torch.cat(window_list, dim=0)\n",
    "        x_tensor = x_tensor.unsqueeze(0)\n",
    "    else:\n",
    "        window_list = torch.cat(window_list, dim=0).unsqueeze(0)\n",
    "        x_tensor = torch.cat((x_tensor, window_list), dim=0)\n",
    "\n",
    "    if y_tensor is None:\n",
    "        y_tensor = tensor[i+77].unsqueeze(0)\n",
    "    else:\n",
    "        y_tensor = torch.cat((y_tensor, tensor[i+77].unsqueeze(0)), dim=0)\n",
    "\n",
    "x_tensor = x_tensor.permute(0, 1, 3, 2)\n",
    "y_tensor = y_tensor.permute(0, 2, 1).unsqueeze(1)\n",
    "print(f\"X Tensor Shape: {x_tensor.shape}\")\n",
    "print(f\"Y Tensor Shape: {y_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayhour_to_timelabel(day, hour):\n",
    "    if day < 5: # workday\n",
    "        time_label = hour\n",
    "    else: # holiday\n",
    "        time_label = hour + 24\n",
    "    return time_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_forward_1h (hour, day):\n",
    "    hour += 1\n",
    "    if hour == 24:\n",
    "        day += 1\n",
    "        hour = 0\n",
    "        if day == 7:\n",
    "            day = 0\n",
    "    return hour, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "day=4\n",
    "hour=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_label = torch.zeros(4315)\n",
    "for i in range(time_label.size(0)):\n",
    "    time_label[i] = dayhour_to_timelabel(day, hour)\n",
    "    hour, day = move_forward_1h(hour, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C Tensor Shape: torch.Size([4315, 1, 128, 2])\n"
     ]
    }
   ],
   "source": [
    "max_CP_inflow = {}\n",
    "max_CP_outflow = {}\n",
    "c = torch.empty_like(y_tensor)\n",
    "\n",
    "for i in range(y_tensor.size(0)):\n",
    "    for node in range(y_tensor.size(2)):\n",
    "        inflow = y_tensor[i][0][node][0]\n",
    "        outflow = y_tensor[i][0][node][1]\n",
    "        if node not in max_CP_inflow:\n",
    "            max_CP_inflow[node] = inflow\n",
    "        if node not in max_CP_outflow:\n",
    "            max_CP_outflow[node] = outflow\n",
    "        if inflow > max_CP_inflow[node]:\n",
    "            max_CP_inflow[node] = inflow\n",
    "        if outflow > max_CP_outflow[node]:\n",
    "            max_CP_outflow[node] = outflow\n",
    "        if max_CP_inflow[node] == 0:\n",
    "            c[i][0][node][0] = 0\n",
    "        else:\n",
    "            c[i][0][node][0] = math.ceil(5 * inflow / max_CP_inflow[node])\n",
    "        if max_CP_outflow[node] == 0:\n",
    "            c[i][0][node][1] = 0\n",
    "        else:\n",
    "            c[i][0][node][1] = math.ceil(5 * outflow / max_CP_outflow[node])\n",
    "\n",
    "print(f\"C Tensor Shape: {c.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: torch.Size([3020, 19, 128, 2]), torch.Size([3020, 1, 128, 2]), torch.Size([3020, 1, 128, 2]), torch.Size([3020])\n",
      "val shape: torch.Size([863, 19, 128, 2]), torch.Size([863, 1, 128, 2]), torch.Size([863, 1, 128, 2]), torch.Size([863])\n",
      "test shape: torch.Size([432, 19, 128, 2]), torch.Size([432, 1, 128, 2]), torch.Size([432, 1, 128, 2]), torch.Size([432])\n"
     ]
    }
   ],
   "source": [
    "# create training, validation, and test sets for none OOD cases\n",
    "def create_train_val_test_sets (x_tensor, y_tensor, c, time_label):\n",
    "    # shuffle the data\n",
    "    torch.manual_seed(0)\n",
    "    indices = torch.randperm(x_tensor.size(0))\n",
    "    x_tensor = x_tensor[indices]\n",
    "    y_tensor = y_tensor[indices]\n",
    "    c = c[indices]\n",
    "    time_label = time_label[indices]\n",
    "\n",
    "    # split the data\n",
    "    train_size = int(0.7 * x_tensor.size(0))\n",
    "    val_size = int(0.2 * x_tensor.size(0))\n",
    "\n",
    "    x_train = x_tensor[:train_size]\n",
    "    y_train = y_tensor[:train_size]\n",
    "    c_train = c[:train_size]\n",
    "    time_label_train = time_label[:train_size]\n",
    "\n",
    "    x_val = x_tensor[train_size:train_size+val_size]\n",
    "    y_val = y_tensor[train_size:train_size+val_size]\n",
    "    c_val = c[train_size:train_size+val_size]\n",
    "    time_label_val = time_label[train_size:train_size+val_size]\n",
    "\n",
    "    x_test = x_tensor[train_size+val_size:]\n",
    "    y_test = y_tensor[train_size+val_size:]\n",
    "    c_test = c[train_size+val_size:]\n",
    "    time_label_test = time_label[train_size+val_size:]\n",
    "\n",
    "    return x_train, y_train, c_train, time_label_train, x_val, y_val, c_val, time_label_val, x_test, y_test, c_test, time_label_test\n",
    "\n",
    "x_train, y_train, c_train, time_label_train, x_val, y_val, c_val, time_label_val, x_test, y_test, c_test, time_label_test = create_train_val_test_sets(x_tensor, y_tensor, c, time_label)\n",
    "print(f\"train shape: {x_train.shape}, {y_train.shape}, {c_train.shape}, {time_label_train.shape}\")\n",
    "print(f\"val shape: {x_val.shape}, {y_val.shape}, {c_val.shape}, {time_label_val.shape}\")\n",
    "print(f\"test shape: {x_test.shape}, {y_test.shape}, {c_test.shape}, {time_label_test.shape}\")\n",
    "\n",
    "# np.savez('train.npz', x=x_train, y=y_train, time_label=time_label_train, c=c_train)\n",
    "# np.savez('val.npz', x=x_val, y=y_val, time_label=time_label_val, c=c_val)\n",
    "# np.savez('test.npz', x=x_test, y=y_test, time_label=time_label_test, c=c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_test_sets (tensor):\n",
    "    # shuffle the data\n",
    "    torch.manual_seed(0)\n",
    "    indices = torch.randperm(x_tensor.size(0))\n",
    "    tensor = tensor[indices]\n",
    "\n",
    "    # split the data\n",
    "    train_size = int(0.7 * tensor.size(0))\n",
    "    val_size = int(0.2 * tensor.size(0))\n",
    "\n",
    "    tensor_train = tensor[:train_size]\n",
    "\n",
    "    tensor_val = tensor[train_size:train_size+val_size]\n",
    "\n",
    "    tensor_test = tensor[train_size+val_size:]\n",
    "\n",
    "    return tensor_train, tensor_val, tensor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Shape: (128, 4392, 2)\n",
      "Spatial mean Shape: (128, 2)\n",
      "Spatial median Shape: (128, 2)\n",
      "Spatial Shape: (128, 4)\n"
     ]
    }
   ],
   "source": [
    "spatial = tensor.permute(2, 0, 1).numpy()\n",
    "scaler = StandardScaler()\n",
    "spatial = scaler.fit_transform(spatial.reshape(-1, spatial.shape[-1])).reshape(spatial.shape)\n",
    "print(f\"Spatial Shape: {spatial.shape}\")\n",
    "spatial_mean = np.mean(spatial, axis=1)\n",
    "print(f\"Spatial mean Shape: {spatial_mean.shape}\")\n",
    "spatial_median = np.median(spatial, axis=1)\n",
    "print(f\"Spatial median Shape: {spatial_median.shape}\")\n",
    "spatial = np.concatenate((spatial_mean, spatial_median), axis=1)\n",
    "print(f\"Spatial Shape: {spatial.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\anaconda3\\envs\\dgl\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"d:\\Anaconda\\anaconda3\\envs\\dgl\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"d:\\Anaconda\\anaconda3\\envs\\dgl\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"d:\\Anaconda\\anaconda3\\envs\\dgl\\lib\\subprocess.py\", line 1495, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "  File \"d:\\Anaconda\\anaconda3\\envs\\dgl\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc8 in position 26: invalid continuation byte\n",
      "d:\\Anaconda\\anaconda3\\envs\\dgl\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "'NoneType' object has no attribute 'splitlines'\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"d:\\Anaconda\\anaconda3\\envs\\dgl\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 262, in _count_physical_cores\n",
      "    cpu_info = cpu_info.stdout.splitlines()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=2, the average silhouette score is: 0.7131382195826163\n",
      "For k=3, the average silhouette score is: 0.7150724273057647\n",
      "For k=4, the average silhouette score is: 0.6793965150110867\n",
      "For k=5, the average silhouette score is: 0.6487641306319236\n",
      "Best K: 3\n"
     ]
    }
   ],
   "source": [
    "n_clusters= range(2, 6)\n",
    "best_k = None\n",
    "best_score = -1\n",
    "best_cluster = None\n",
    "for n in n_clusters:\n",
    "    cluster = KMeans(n_clusters=n, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    cluster_labels = cluster.fit_predict(spatial)\n",
    "\n",
    "    silhouette_avg = silhouette_score(spatial, cluster_labels)\n",
    "\n",
    "    print(f\"For k={n}, the average silhouette score is: {silhouette_avg}\")\n",
    "\n",
    "    if silhouette_avg > best_score:\n",
    "        best_score = silhouette_avg\n",
    "        best_k = n\n",
    "        best_cluster = cluster\n",
    "\n",
    "print(f\"Best K: {best_k}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 1, 2, 2,\n",
       "       0, 0, 0, 2, 2, 1, 1, 2, 0, 0, 0, 1, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 0, 2, 1, 1, 2, 0, 0, 0, 0, 2,\n",
       "       1, 1, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_labels = best_cluster.fit_predict(spatial)\n",
    "np.save(\"cluster_labels.npy\", cluster_labels)\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_c0 shape: torch.Size([432, 19, 81, 2]), y_test_c0 shape: torch.Size([432, 1, 81, 2])\n",
      "x_test_c1 shape: torch.Size([432, 19, 17, 2]), y_test_c1 shape: torch.Size([432, 1, 17, 2])\n",
      "x_test_c2 shape: torch.Size([432, 19, 30, 2]), y_test_c2 shape: torch.Size([432, 1, 30, 2])\n"
     ]
    }
   ],
   "source": [
    "x_test_c0 = torch.tensor([])\n",
    "x_test_c1 = torch.tensor([])\n",
    "x_test_c2 = torch.tensor([])\n",
    "y_test_c0 = torch.tensor([])\n",
    "y_test_c1 = torch.tensor([])\n",
    "y_test_c2 = torch.tensor([])\n",
    "temp_x = x_test.permute(2, 0, 1, 3)\n",
    "temp_y = y_test.permute(2, 0, 1, 3)\n",
    "for i in range(cluster_labels.shape[0]):\n",
    "    label = cluster_labels[i]\n",
    "    if label == 0:\n",
    "        x_test_c0 = torch.cat((x_test_c0, temp_x[i].unsqueeze(0)), dim=0)\n",
    "        y_test_c0 = torch.cat((y_test_c0, temp_y[i].unsqueeze(0)), dim=0)\n",
    "    elif label == 1:\n",
    "        x_test_c1 = torch.cat((x_test_c1, temp_x[i].unsqueeze(0)), dim=0)\n",
    "        y_test_c1 = torch.cat((y_test_c1, temp_y[i].unsqueeze(0)), dim=0)\n",
    "    else:\n",
    "        x_test_c2 = torch.cat((x_test_c2, temp_x[i].unsqueeze(0)), dim=0)\n",
    "        y_test_c2 = torch.cat((y_test_c2, temp_y[i].unsqueeze(0)), dim=0)\n",
    "\n",
    "x_test_c0 = x_test_c0.permute(1, 2, 0, 3)\n",
    "x_test_c1 = x_test_c1.permute(1, 2, 0, 3)\n",
    "x_test_c2 = x_test_c2.permute(1, 2, 0, 3)\n",
    "y_test_c0 = y_test_c0.permute(1, 2, 0, 3)\n",
    "y_test_c1 = y_test_c1.permute(1, 2, 0, 3)\n",
    "y_test_c2 = y_test_c2.permute(1, 2, 0, 3)\n",
    "\n",
    "print(f\"x_test_c0 shape: {x_test_c0.shape}, y_test_c0 shape: {y_test_c0.shape}\")\n",
    "print(f\"x_test_c1 shape: {x_test_c1.shape}, y_test_c1 shape: {y_test_c1.shape}\")\n",
    "print(f\"x_test_c2 shape: {x_test_c2.shape}, y_test_c2 shape: {y_test_c2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_list = [0, 1, 2, 3, 4, 5, 6]\n",
    "hour_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "def split_work_holiday (tensor, day, hour): # tensor of size (4315, 19, 2, 128)\n",
    "    workday_tensor = None\n",
    "    holiday_tensor = None\n",
    "    for i in range(tensor.size(0)):\n",
    "        if day <= 4:\n",
    "            if workday_tensor is None:\n",
    "                workday_tensor = tensor[i].unsqueeze(0)\n",
    "                hour, day = move_forward_1h(hour, day)\n",
    "            else:\n",
    "                workday_tensor = torch.cat((workday_tensor, tensor[i].unsqueeze(0)), dim=0)\n",
    "                hour, day = move_forward_1h(hour, day)\n",
    "        else:\n",
    "            if holiday_tensor is None:\n",
    "                holiday_tensor = tensor[i].unsqueeze(0)\n",
    "                hour, day = move_forward_1h(hour, day)\n",
    "            else:\n",
    "                holiday_tensor = torch.cat((holiday_tensor, tensor[i].unsqueeze(0)), dim=0)\n",
    "                hour, day = move_forward_1h(hour, day)\n",
    "    \n",
    "    return workday_tensor, holiday_tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_workday_tensor, x_holiday_tensor = split_work_holiday(x_tensor, day, hour)\n",
    "y_workday_tensor, y_holiday_tensor = split_work_holiday(y_tensor, day, hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3073, 19, 128, 2])\n",
      "torch.Size([3073, 1, 128, 2])\n",
      "torch.Size([1242, 19, 128, 2])\n",
      "torch.Size([1242, 1, 128, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x_workday_tensor.shape)\n",
    "print(y_workday_tensor.shape)\n",
    "print(x_holiday_tensor.shape)\n",
    "print(y_holiday_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_workday_tensor = y_workday_tensor.permute(0, 1, 3, 2)\n",
    "y_holiday_tensor = y_holiday_tensor.permute(0, 1, 3, 2)\n",
    "x_workday_tensor = x_workday_tensor.permute(0, 1, 3, 2)\n",
    "x_holiday_tensor = x_holiday_tensor.permute(0, 1, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3073, 19, 2, 128])\n",
      "torch.Size([3073, 1, 2, 128])\n",
      "torch.Size([1242, 19, 2, 128])\n",
      "torch.Size([1242, 1, 2, 128])\n",
      "torch.Size([4315, 19, 128, 2])\n",
      "torch.Size([4315, 1, 128, 2])\n",
      "torch.Size([4315, 1, 128, 2])\n",
      "torch.Size([4315])\n"
     ]
    }
   ],
   "source": [
    "print(x_workday_tensor.shape)\n",
    "print(y_workday_tensor.shape)\n",
    "print(x_holiday_tensor.shape)\n",
    "print(y_holiday_tensor.shape)\n",
    "print(x_tensor.shape)\n",
    "print(y_tensor.shape)\n",
    "print(c.shape)\n",
    "print(time_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "workday_scaler = normalize_data(x_workday_tensor, 'Standard')\n",
    "holiday_scaler = normalize_data(x_workday_tensor, 'Standard')\n",
    "total_scalar = normalize_data(x_tensor, 'Standard')\n",
    "x_workday_tensor = workday_scaler.transform(x_workday_tensor).to(torch.float)\n",
    "x_holiday_tensor = holiday_scaler.transform(x_holiday_tensor).to(torch.float)\n",
    "y_workday_tensor = workday_scaler.transform(y_workday_tensor).to(torch.float)\n",
    "y_holiday_tensor = holiday_scaler.transform(y_holiday_tensor).to(torch.float)\n",
    "x_total_tensor = total_scalar.transform(x_tensor).to(torch.float)\n",
    "y_total_tensor = total_scalar.transform(y_tensor).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "workday_dataset = torch.utils.data.TensorDataset(x_workday_tensor, y_workday_tensor)\n",
    "holiday_dataset = torch.utils.data.TensorDataset(x_holiday_tensor, y_holiday_tensor)\n",
    "total_dataset = torch.utils.data.TensorDataset(x_total_tensor, y_total_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "workday_total = len(workday_dataset)\n",
    "holiday_total = len(holiday_dataset)\n",
    "total_total = len(total_dataset)\n",
    "workday_train_size = int(workday_total * 0.7)\n",
    "holiday_train_size = int(holiday_total * 0.7)\n",
    "total_train_size = int(total_total * 0.7)\n",
    "workday_val_size = int(workday_total * 0.1)\n",
    "holiday_val_size = int(holiday_total * 0.1)\n",
    "total_val_size = int(total_total * 0.1)\n",
    "workday_test_size = workday_total - workday_train_size - workday_val_size\n",
    "holiday_test_size = holiday_total - holiday_train_size - holiday_val_size\n",
    "total_test_size = total_total - total_train_size - total_val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "workday_train, workday_val, workday_test = torch.utils.data.random_split(workday_dataset, [workday_train_size, workday_val_size, workday_test_size])\n",
    "holiday_train, holiday_val, holiday_test = torch.utils.data.random_split(holiday_dataset, [holiday_train_size, holiday_val_size, holiday_test_size])\n",
    "total_train, total_val, total_test = torch.utils.data.random_split(total_dataset, [total_train_size, total_val_size, total_test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "workday_test_dataloader = torch.utils.data.DataLoader(\n",
    "    workday_test,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "holiday_test_dataloader = torch.utils.data.DataLoader(\n",
    "    holiday_test,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "total_test_dataloader = torch.utils.data.DataLoader(\n",
    "    total_test,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "workday_set = {}\n",
    "holiday_set = {}\n",
    "total_set = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "workday_set['dataloader'] = workday_test_dataloader\n",
    "workday_set['scaler'] = workday_scaler\n",
    "holiday_set['dataloader'] = holiday_test_dataloader\n",
    "holiday_set['scaler'] = holiday_scaler\n",
    "total_set['dataloader'] = total_test_dataloader\n",
    "total_set['scaler'] = total_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"workday_test_dataloader.pkl\", \"wb\") as f:\n",
    "    pickle.dump(workday_set, f)\n",
    "\n",
    "with open(\"holiday_test_dataloader.pkl\", \"wb\") as f:\n",
    "    pickle.dump(holiday_set, f)\n",
    "\n",
    "with open(\"total_test_dataloader.pkl\", \"wb\") as f:\n",
    "    pickle.dump(total_set, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
